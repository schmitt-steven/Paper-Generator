import json
from pathlib import Path
from typing import Any, Dict


class Settings:
    """
    Configuration settings for the paper generator pipeline.
    
    Note: MLX embedding models are NOT supported by LM Studio yet, use GGUF instead :(
    See https://github.com/lmstudio-ai/lmstudio-bug-tracker/issues/808
    
    Settings can be saved to and loaded from user_settings.json to persist changes across sessions.
    """
    
    _SETTINGS_FILE = Path("user_settings.json")
    
    @classmethod
    def save_to_file(cls) -> None:
        """Save current settings to user_settings.json file."""
        settings_dict = {}
        
        # Get all class attributes (excluding private attributes and methods)
        for key in dir(cls):
            if key.startswith('_'):
                continue
            try:
                value = getattr(cls, key)
                # Only save non-callable attributes (skip methods)
                if not callable(value):
                    settings_dict[key] = value
            except AttributeError:
                continue
        
        try:
            with open(cls._SETTINGS_FILE, 'w', encoding='utf-8') as f:
                json.dump(settings_dict, f, indent=2, ensure_ascii=False)
            print(f"[Settings] Saved settings to {cls._SETTINGS_FILE}")
        except Exception as e:
            print(f"[Settings] Failed to save settings: {e}")
    
    @classmethod
    def load_from_file(cls) -> None:
        """Load settings from user_settings.json file if it exists."""
        if not cls._SETTINGS_FILE.exists():
            return
        
        try:
            with open(cls._SETTINGS_FILE, 'r', encoding='utf-8') as f:
                settings_dict = json.load(f)
            
            # Update class attributes with loaded values
            for key, value in settings_dict.items():
                if hasattr(cls, key):
                    setattr(cls, key, value)
            
            print(f"[Settings] Loaded settings from {cls._SETTINGS_FILE}")
        except Exception as e:
            print(f"[Settings] Failed to load settings: {e}")
    
    @classmethod
    def get_all_settings(cls) -> dict[str, Any]:
        """Get all settings as a dictionary."""
        settings_dict = {}
        for key in dir(cls):
            if key.startswith('_'):
                continue
            try:
                value = getattr(cls, key)
                if not callable(value):
                    settings_dict[key] = value
            except AttributeError:
                continue
        return settings_dict
    
    # Context Analysis Phase
    CODE_ANALYSIS_MODEL =    "qwen/qwen3-next-80b"  
    NOTES_ANALYSIS_MODEL =   "qwen/qwen3-next-80b"  
    PAPER_CONCEPTION_MODEL = "qwen3-next-80b-a3b-thinking-mlx"  
    
    # Paper Search Phase
    LITERATURE_SEARCH_MODEL =             "qwen/qwen3-next-80b"  
    PAPER_ANALYSIS_MODEL =                "qwen/qwen3-next-80b"
    PAPER_RANKING_EMBEDDING_MODEL =       "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    LIMITATION_ANALYSIS_EMBEDDING_MODEL = "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    
    # Hypothesis Generation Phase
    HYPOTHESIS_BUILDER_MODEL =           "qwen3-next-80b-a3b-thinking-mlx"
    HYPOTHESIS_BUILDER_EMBEDDING_MODEL = "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    
    # Experimentation Phase
    EXPERIMENT_PLAN_MODEL =          "qwen3-next-80b-a3b-thinking-mlx"
    EXPERIMENT_CODE_WRITE_MODEL =    "qwen/qwen3-next-80b"  
    EXPERIMENT_CODE_FIX_MODEL =      "qwen/qwen3-next-80b"  
    EXPERIMENT_CODE_IMPROVE_MODEL =  "qwen/qwen3-next-80b" 
    EXPERIMENT_VALIDATION_MODEL =    "qwen3-next-80b-a3b-thinking-mlx" 
    EXPERIMENT_PLOT_CAPTION_MODEL =  "qwen/qwen3-vl-4b"  # Must be a VISION model!
    EXPERIMENT_VERDICT_MODEL =       "qwen3-next-80b-a3b-thinking-mlx"

    
    # Paper Writing Phase
    PAPER_INDEXING_EMBEDDING_MODEL = "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    PAPER_EMBEDDING_BATCH_SIZE =     64  # Number of text chunks to embed at once

    EVIDENCE_GATHERING_MODEL =       "qwen/qwen3-next-80b"  
    PAPER_WRITING_MODEL =            "qwen/qwen3-next-80b"

    EVIDENCE_INITIAL_CHUNKS =        12  # Number of chunks retrieved from vector search
    EVIDENCE_FILTERED_CHUNKS =       8   # Number of chunks after LLM filtering/scoring
    EVIDENCE_AGENTIC_ITERATIONS =    3   # Number of agentic search iterations
    
    # LaTeX Generation Phase
    LATEX_GENERATION_MODEL = "qwen/qwen3-next-80b"

    # UI Settings
    FONT_SIZE_BASE = 16

    

    # LaTeX Data
    LATEX_TITLE = ""  # If empty, title will be generated by LLM
    LATEX_AUTHORS = [
        {
            "name": "Qwen3",
            "affiliation": "University of Qwen",
            "department": "Department of Computer Science",
            "address": "Buckingham Palace, London, UK",
            "email": "qwen.rocks@china.gov"
        },
        {
            "name": "Human",
            "affiliation": "Tech Corp",
            "department": "AI Department",
            "address": "Mannheim, Germany",
            "email": "second@guy.com"
        },
    ]
    

    # Set to True to load existing files from output/ and skip the respective step
    LOAD_PAPER_CONCEPT = True

    LOAD_SEARCH_QUERIES = True
    LOAD_PAPERS =         True
    LOAD_PAPER_RANKING =  True

    LOAD_FINDINGS =    True
    LOAD_LIMITATIONS = True
    LOAD_HYPOTHESES =  True

    LOAD_EXPERIMENT_PLAN =   True
    LOAD_EXPERIMENT_CODE =   True
    LOAD_EXPERIMENT_RESULT = True

    LOAD_PAPER_EMBEDDINGS =      True
    LOAD_PAPER_WRITING_PROMPTS = True
    LOAD_PAPER_DRAFT =           True
    
    LOAD_LATEX =                 False

    # Acknowledgements Generation
    GENERATE_ACKNOWLEDGEMENTS = True  # Set to False to skip acknowledgements section entirely


# Load settings from file on import (if file exists)
Settings.load_from_file()
