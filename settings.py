class Settings:
    """
    Configuration settings for the paper generator pipeline.
    
    Note: MLX embedding models are NOT supported by LM Studio yet, use GGUF instead :(
    See https://github.com/lmstudio-ai/lmstudio-bug-tracker/issues/808
    """
    
    # Context Analysis Phase
    CODE_ANALYSIS_MODEL =    "qwen/qwen3-next-80b"  
    NOTES_ANALYSIS_MODEL =   "qwen/qwen3-next-80b"  
    PAPER_CONCEPTION_MODEL = "qwen3-next-80b-a3b-thinking-mlx"  
    
    # Paper Search Phase
    LITERATURE_SEARCH_MODEL =             "qwen/qwen3-next-80b"  
    PAPER_ANALYSIS_MODEL =                "qwen/qwen3-next-80b"
    PAPER_RANKING_EMBEDDING_MODEL =       "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    LIMITATION_ANALYSIS_EMBEDDING_MODEL = "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    
    # Hypothesis Generation Phase
    HYPOTHESIS_BUILDER_MODEL =           "qwen3-next-80b-a3b-thinking-mlx"
    HYPOTHESIS_BUILDER_EMBEDDING_MODEL = "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    
    # Experimentation Phase
    EXPERIMENT_PLAN_MODEL =          "qwen3-next-80b-a3b-thinking-mlx"
    EXPERIMENT_CODE_WRITE_MODEL =    "qwen/qwen3-next-80b"  
    EXPERIMENT_CODE_FIX_MODEL =      "qwen/qwen3-next-80b"  
    EXPERIMENT_CODE_IMPROVE_MODEL =  "qwen/qwen3-next-80b" 
    EXPERIMENT_VALIDATION_MODEL =    "qwen3-next-80b-a3b-thinking-mlx" 
    EXPERIMENT_PLOT_CAPTION_MODEL =  "qwen/qwen3-vl-4b"  # Must be a VISION model!
    EXPERIMENT_VERDICT_MODEL =       "qwen3-next-80b-a3b-thinking-mlx"

    
    # Paper Writing Phase
    PAPER_INDEXING_EMBEDDING_MODEL = "text-embedding-qwen3-embedding-4b@q5_0"  # Must be an embedding model!
    PAPER_EMBEDDING_BATCH_SIZE =     64  # Number of text chunks to embed at once
    EVIDENCE_GATHERING_MODEL =       "qwen/qwen3-next-80b"  
    PAPER_WRITING_MODEL =            "qwen/qwen3-next-80b"
    
    # LaTeX Generation Phase
    LATEX_GENERATION_MODEL = "qwen/qwen3-next-80b"
    

    # LaTeX Metadata (IEEEtran Conference/Journal Format)
    LATEX_TITLE = ""  # If empty, title will be generated by LLM
    LATEX_AUTHORS = [
        {
            "name": "Qwen3",
            "affiliation": "University of Qwen",
            "department": "Department of Computer Science",
            "address": "Buckingham Palace, London, UK",
            "email": "qwen.rocks@china.gov"
        },
        {
            "name": "Human",
            "affiliation": "Tech Corp",
            "department": "AI Department",
            "address": "Mannheim, Germany",
            "email": "second@guy.com"
        },
    ]
    

    # Set to True to load existing files from output/ and skip the respective step
    LOAD_PAPER_CONCEPT = True

    LOAD_SEARCH_QUERIES = True
    LOAD_PAPERS =         True
    LOAD_PAPER_RANKING =  True

    LOAD_FINDINGS =    True
    LOAD_LIMITATIONS = True
    LOAD_HYPOTHESES =  True

    LOAD_EXPERIMENT_PLAN =   True
    LOAD_EXPERIMENT_CODE =   True
    LOAD_EXPERIMENT_RESULT = True

    LOAD_PAPER_EMBEDDINGS =      True
    LOAD_PAPER_WRITING_PROMPTS = False
    LOAD_PAPER_DRAFT =           False
    LOAD_LATEX =                 False
