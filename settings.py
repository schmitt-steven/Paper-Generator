class Settings:
    """Configuration settings for the paper generator pipeline."""
    
    # Context Analysis Phase
    CODE_ANALYSIS_MODEL =    "qwen/qwen3-next-80b"  
    NOTES_ANALYSIS_MODEL =   "qwen/qwen3-next-80b"  
    PAPER_CONCEPTION_MODEL = "qwen/qwen3-next-80b-a3b-thinking-mlx"  
    
    # Paper Search Phase
    LITERATURE_SEARCH_MODEL =             "qwen/qwen3-next-80b"  
    PAPER_ANALYSIS_MODEL =                "qwen/qwen3-next-80b"
    PAPER_RANKING_EMBEDDING_MODEL =       "qwen3-embedding-4b-dwq"  # Must be an embedding model!
    LIMITATION_ANALYSIS_EMBEDDING_MODEL = "qwen3-embedding-4b-dwq"  # Must be an embedding model!
    
    # Hypothesis Generation Phase
    HYPOTHESIS_BUILDER_MODEL =           "qwen3-next-80b-a3b-thinking-mlx"
    HYPOTHESIS_BUILDER_EMBEDDING_MODEL = "qwen3-embedding-4b-dwq"  # Must be an embedding model!
    
    # Experimentation Phase
    EXPERIMENT_PLAN_MODEL =          "qwen3-next-80b-a3b-thinking-mlx"
    EXPERIMENT_CODE_WRITE_MODEL =    "qwen/qwen3-next-80b"  
    EXPERIMENT_CODE_FIX_MODEL =      "qwen/qwen3-next-80b"  
    EXPERIMENT_CODE_IMPROVE_MODEL =  "qwen/qwen3-next-80b" 
    EXPERIMENT_VALIDATION_MODEL =    "qwen/qwen3-next-80b-a3b-thinking-mlx" 
    EXPERIMENT_VERDICT_MODEL =       "qwen3-next-80b-a3b-thinking-mlx"
    EXPERIMENT_PLOT_CAPTION_MODEL =  "qwen/qwen3-next-80b"  # Must be a VISION model!
    
    # Paper Writing Phase
    PAPER_INDEXING_EMBEDDING_MODEL = "qwen3-embedding-4b-dwq"  # Must be an embedding model!
    EVIDENCE_GATHERING_MODEL =       "qwen3-next-80b-a3b-thinking-mlx"  
    PAPER_WRITING_MODEL =            "qwen/qwen3-next-80b"
    
    # LaTeX Generation Phase
    LATEX_GENERATION_MODEL = "qwen/qwen3-next-80b"
    

    # LaTeX Metadata (IEEEtran Conference/Journal Format)
    LATEX_TITLE = ""  # If empty, title will be generated by LLM
    LATEX_AUTHORS = [
        {
            "name": "Qwen3",
            "affiliation": "University of Qwen",
            "department": "Department of Computer Science",
            "address": "Buckingham Palace, London, UK",
            "email": "qwen.rocks@china.gov"
        },
        {
            "name": "Second Author",
            "affiliation": "Tech Corp",
            "department": "AI Department",
            "address": "Mannheim, Germany",
            "email": "second@guy.com"
        },
    ]
    

    # Set to True to load existing files from output/ and skip the respective step
    LOAD_PAPER_CONCEPT =     True

    LOAD_SEARCH_QUERIES =    True
    LOAD_PAPERS =            True
    LOAD_PAPER_RANKING =     True

    LOAD_FINDINGS =          True
    LOAD_LIMITATIONS =       True
    LOAD_HYPOTHESES =        True  # if true, ignores LOAD_FINDINGS/LIMITATIONS

    LOAD_EXPERIMENT_PLAN =   False
    LOAD_EXPERIMENT_CODE =   False
    LOAD_EXPERIMENT_RESULT = False  # if true, ignores LOAD_EXPERIMENT_PLAN/CODE

    LOAD_PAPER_DRAFT =       False
    LOAD_LATEX =             False  # if true, ignores LOAD_PAPER_DRAFT
