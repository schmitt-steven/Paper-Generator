[
  {
    "label": "Persistent transition memory in Q-learning",
    "query": "abs:%22persistent%20memory%22+AND+abs:%22Q-learning%22",
    "description": "Foundational model-free methods with persistent memory for value propagation"
  },
  {
    "label": "Backward reward propagation deterministic RL",
    "query": "abs:%22backward%20propagation%22+AND+abs:%22deterministic%20reinforcement%20learning%22",
    "description": "Backward reward propagation in deterministic RL environments"
  },
  {
    "label": "Dyna-Q versus direct transition reuse",
    "query": "abs:%22Dyna-Q%22+AND+abs:%22model-free%22",
    "description": "Dyna-Q vs model-free methods using observed transitions"
  },
  {
    "label": "Eligibility traces cross-episode propagation",
    "query": "abs:%22eligibility%20traces%22+AND+abs:%22value%20propagation%22",
    "description": "Eligibility traces and value propagation across episodes"
  },
  {
    "label": "Sample efficiency sparse rewards RL",
    "query": "abs:%22sample%20efficiency%22+AND+abs:%22sparse%20rewards%22",
    "description": "Sample efficiency in sparse reward environments"
  },
  {
    "label": "Backward induction cross-episode RL",
    "query": "abs:%22backward%20induction%22+AND+abs:%22multi-episode%22",
    "description": "Backward induction methods in RL with multi-episode memory"
  },
  {
    "label": "Value iteration model-free RL",
    "query": "abs:%22value%20iteration%22+AND+abs:%22model-free%22",
    "description": "Value iteration without transition model knowledge"
  },
  {
    "label": "Episodic memory reinforcement learning",
    "query": "abs:%22episodic%20memory%22+AND+abs:%22reinforcement%20learning%22",
    "description": "Episodic memory for accelerating RL convergence"
  },
  {
    "label": "Transition graph Q-value update",
    "query": "abs:%22transition%20graph%22+AND+abs:%22Q-value%22",
    "description": "Transition graphs for value function updates"
  },
  {
    "label": "Convergence rate model-based RL",
    "query": "abs:%22convergence%20rate%22+AND+abs:%22model-based%22",
    "description": "Convergence rate improvements in model-based RL"
  },
  {
    "label": "Prioritized sweeping backward update",
    "query": "abs:%22prioritized%20sweeping%22+AND+abs:%22backward%20update%22",
    "description": "Prioritized sweeping and backward value updates"
  },
  {
    "label": "RETRACE cross-trajectory rewards",
    "query": "abs:%22RETRACE%22+AND+abs:%22reward%20propagation%22",
    "description": "RETRACE and cross-trajectory reward propagation"
  },
  {
    "label": "Survey sample efficient reinforcement learning",
    "query": "abs:%22survey%22+AND+abs:%22sample%20efficient%20reinforcement%20learning%22",
    "description": "Survey papers on sample-efficient RL methods"
  },
  {
    "label": "Bellman update historical transitions",
    "query": "abs:%22Bellman%20optimality%22+AND+abs:%22historical%20transitions%22",
    "description": "Bellman updates using historical transitions"
  },
  {
    "label": "Model-free dynamic programming RL",
    "query": "abs:%22model-free%22+AND+abs:%22dynamic%20programming%22",
    "description": "Model-free dynamic programming hybrids"
  }
]